{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrmVSlAAcKh7"
      },
      "source": [
        " # Práctica Guiada 2.\n",
        " ----\n",
        "  \n",
        "  Universidad : UTEC \\\\\n",
        "  Curso       : Inteligencia Artificial \\\\\n",
        "  Profesor    : Cristian López Del Alamo \\\\\n",
        "  Tema        : Regresión Lineal Múltiple \\\\\n",
        "  \n",
        "\n",
        " ----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFlH9PtJHOHl"
      },
      "source": [
        "\n",
        "\n",
        "1.  En esta práctica se pide realizar pruebas utilizando   diferentes funciones de pérdida.\n",
        "\n",
        "2.  Su equipo debe implementar el algoritmo de machine learning para  regresión lineal múltiple y realizar las correspondientes pruebas usando el siguiente  [Dataset](\n",
        "https://docs.google.com/spreadsheets/d/10wC32tLXK9xHfsQ6DuDSQIqEi4qPLogfThHwATvVgpc/edit?usp=sharing\n",
        ").  \n",
        "\n",
        "3. MSE Loss Function \\\\\n",
        "\n",
        "  $MSE = \\frac{1}{2m}\\sum_{i=0}^m (y_i - h(x_i))^2$\n",
        "\n",
        "4. Utilize todo los datos del dataset para entrenar  y grafique el plano que mejor separa a los datos. [Help](https://stackoverflow.com/questions/36060933/matplotlib-plot-a-plane-and-points-in-3d-simultaneously)\n",
        "\n",
        "Importante: No se olvide de normalizar los datos entre cero y uno, por cada columna.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fZbLdlsloF4",
        "outputId": "f91d70c0-5181-4797-b255-13d68bc3dc42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_DEtwUxFsLp"
      },
      "source": [
        "Crear el DataSet\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RgZIGVKlFuvn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv('db.csv')\n",
        "X = dataset[[\"Year\",\"Population\"]]\n",
        "Y = dataset[\"Employed\"]\n",
        "\n",
        "# X['ones'] = 1\n",
        "# print(X)\n",
        "\n",
        "# print(Y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRbGcXmWIaKO"
      },
      "source": [
        "# Modelo\n",
        "\n",
        "Nota: Antes añadir Añadir una columna de nx1 a X con valor 1.\n",
        "\n",
        "$h(X) = X*W^t$\n",
        "\n",
        "$h(x_i) = x_{i1}w_1 + x_{i2}w_2 + b$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2NnYyf2oG1Fw"
      },
      "outputs": [],
      "source": [
        "\n",
        "def h(X, W):\n",
        "  return  np.dot(X,W.T)\n",
        "\n",
        "    # write your code here\n",
        "    # your code returns a  n by 1 vector. This  vector contains the prediction for all data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(h(X, np.array([1,2,3])))\n",
        "# print(h(X, np.array([1,2,3])).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHWVdGjbIUna"
      },
      "source": [
        "# Loss function\n",
        "Nota: La función de pérdida no cambia, solo la llamada a la función h\n",
        "$\\mathcal{L} =  ||Y - XW^t||_2^2$\n",
        "\n",
        "$\\mathcal{L} = \\frac{1}{2n}\\sum_{i=0}^n (y_i - h(x_i))^2$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2FiEbigVG9Hf"
      },
      "outputs": [],
      "source": [
        "def Error(X, W,Y):\n",
        "  Y_pred = h(X,W)\n",
        "  e = Y - Y_pred\n",
        "  return np.dot(e,e.T)/(2*len(Y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV-_CQ87FrdQ"
      },
      "source": [
        "# Cálculo de derivadas\n",
        "Nota: Intente resolver este algoritmo desde un punto de vista matricial.\n",
        "\n",
        "$dw_j = \\frac{1}{m}\\sum_{i=0}^m(y_i - h(x_i))(-x_{ij})$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0RxT6ee6H8Vn"
      },
      "outputs": [],
      "source": [
        "def derivada(X, W, Y):\n",
        "    # write your code here\n",
        "    Y_pred = h(X,W)\n",
        "    e = Y - Y_pred\n",
        "    return np.matmul(e.T,-X)/len(Y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CRCXMYd6PrX"
      },
      "source": [
        "# Actualiación de parámetros\n",
        "\n",
        "Recuerde: $\\frac{\\partial L}{\\partial w}$ representa un vector con todas las derivadas de la función de pérdida con rescto a W.\n",
        "\n",
        "$W  = W - \\alpha*\\frac{\\partial L}{\\partial W} $\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yv06Mc7NJJx6"
      },
      "outputs": [],
      "source": [
        "def update(W, alpha,dw):\n",
        "# W is a (kx1) vector\n",
        "# dW is a (kx1) vector with the derivatives of the loss function with respect to W\n",
        "# alpha is a float number between 0 and 1\n",
        " # write your code here\n",
        " W = W - alpha*dw\n",
        " return W\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7Z5XhYtXYm-"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HSuPO-XiIjem"
      },
      "outputs": [],
      "source": [
        "def train(X, Y, epochs, alfa):\n",
        "    W = np.random.random(X.shape[1])\n",
        "    L = Error(X,W,Y)\n",
        "    loss = []\n",
        "    for i in range(epochs):\n",
        "        dW = derivada(X, W, Y)\n",
        "        W = update(W,alfa, dW)\n",
        "        L = Error(X, W,Y)\n",
        "        loss.append(L)\n",
        "        if ((i%1000)==0):\n",
        "          print(\"loss value error :\" + str(L))\n",
        "    return W, loss\n",
        "\n",
        "\n",
        "\n",
        "def Plot_Loss(epochs,loss):\n",
        "   plt.plot(epochs, loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7tj9436hrJ7",
        "outputId": "98b026f6-a616-4a56-d47f-5a8abc1c8708"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\USUARIO\\AppData\\Local\\Temp\\ipykernel_24372\\2425746741.py:5: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  return np.matmul(e.T,-X)/len(Y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss value error :54610766753.1337\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(Year         NaN\n",
              " Population   NaN\n",
              " dtype: float64,\n",
              " [54610766753.1337,\n",
              "  7985233486182178.0,\n",
              "  1.1676077379193513e+21,\n",
              "  1.7072861200718094e+26,\n",
              "  2.4964085121463833e+31,\n",
              "  3.650270090203039e+36,\n",
              "  5.337456456585574e+41,\n",
              "  7.804474935267711e+46,\n",
              "  1.1411770664670978e+52,\n",
              "  1.6686389639686627e+57,\n",
              "  2.439898306661853e+62,\n",
              "  3.5676403796137027e+67,\n",
              "  5.216634580014156e+72,\n",
              "  7.627808143696946e+77,\n",
              "  1.115344695600503e+83,\n",
              "  1.630866648149931e+88,\n",
              "  2.384667300197981e+93,\n",
              "  3.4868811248819756e+98,\n",
              "  5.098547700154556e+103,\n",
              "  7.455140487942848e+108,\n",
              "  1.090097081827437e+114,\n",
              "  1.593949369204434e+119,\n",
              "  2.330686536035883e+124,\n",
              "  3.407949985243378e+129,\n",
              "  4.983133905975218e+134,\n",
              "  7.286381441160291e+139,\n",
              "  1.0654209882344096e+145,\n",
              "  1.5578677720029274e+150,\n",
              "  2.2779277129383864e+155,\n",
              "  3.330805578384453e+160,\n",
              "  4.870332687899946e+165,\n",
              "  7.121442525724285e+170,\n",
              "  1.0413034775466689e+176,\n",
              "  1.5226029395505171e+181,\n",
              "  2.226363170312157e+186,\n",
              "  3.255407458746697e+191,\n",
              "  4.760084906083734e+196,\n",
              "  6.96023726684262e+201,\n",
              "  1.0177319053454013e+207,\n",
              "  1.4881363830687938e+212,\n",
              "  2.1759658737056998e+217,\n",
              "  3.1817160963216124e+222,\n",
              "  4.652332759406697e+227,\n",
              "  6.802681147218521e+232,\n",
              "  9.946939134384667e+237,\n",
              "  1.454450032302461e+243,\n",
              "  2.1267094006356275e+248,\n",
              "  3.10969285592576e+253,\n",
              "  4.547019755169886e+258,\n",
              "  6.648691562739602e+263,\n",
              "  9.721774233812001e+268,\n",
              "  1.4215262260453962e+274,\n",
              "  2.0785679267337983e+279,\n",
              "  3.0392999769449676e+284,\n",
              "  4.4440906794770855e+289,\n",
              "  6.498187779169886e+294,\n",
              "  9.501706301438796e+299,\n",
              "  1.3893477028811701e+305,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  inf,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "train(X,Y,1000,0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "jUErEwHLKPPx"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "FigureBase.gca() got an unexpected keyword argument 'projection'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\USUARIO\\Desktop\\2023-2\\ML\\semana2\\Tema_2_Regresion_Lineal_Múltiple_2023_1 (1).ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USUARIO/Desktop/2023-2/ML/semana2/Tema_2_Regresion_Lineal_M%C3%BAltiple_2023_1%20%281%29.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m eq \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m \u001b[39m*\u001b[39m x \u001b[39m+\u001b[39m \u001b[39m40\u001b[39m \u001b[39m*\u001b[39m y \u001b[39m+\u001b[39m \u001b[39m100.09\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USUARIO/Desktop/2023-2/ML/semana2/Tema_2_Regresion_Lineal_M%C3%BAltiple_2023_1%20%281%29.ipynb#X22sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/USUARIO/Desktop/2023-2/ML/semana2/Tema_2_Regresion_Lineal_M%C3%BAltiple_2023_1%20%281%29.ipynb#X22sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m ax \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39mgca(projection\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m3d\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USUARIO/Desktop/2023-2/ML/semana2/Tema_2_Regresion_Lineal_M%C3%BAltiple_2023_1%20%281%29.ipynb#X22sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m ax\u001b[39m.\u001b[39mplot_surface(x, y, eq)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USUARIO/Desktop/2023-2/ML/semana2/Tema_2_Regresion_Lineal_M%C3%BAltiple_2023_1%20%281%29.ipynb#X22sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
            "\u001b[1;31mTypeError\u001b[0m: FigureBase.gca() got an unexpected keyword argument 'projection'"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 700x350 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### Plot plane example\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [7.00, 3.50]\n",
        "plt.rcParams[\"figure.autolayout\"] = True\n",
        "\n",
        "x = np.linspace(-10, 10, 100)\n",
        "y = np.linspace(-10, 10, 100)\n",
        "\n",
        "x, y = np.meshgrid(x, y)\n",
        "# ecuacion del plano: x_1w_1 + x_2w_2 + b\n",
        "\n",
        "eq = 0.1 * x + 40 * y + 100.09\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.gca(projection='3d')\n",
        "\n",
        "ax.plot_surface(x, y, eq)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nis8QDOFXep7"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9T4hkAK6TIW"
      },
      "outputs": [],
      "source": [
        "# Change the values of umbral and alpha and try to obtain a good result\n",
        "\n",
        "W = train(x, y, 1000,  0.001)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
